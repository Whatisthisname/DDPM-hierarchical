{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "states = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _cosine_variance_schedule(timesteps, epsilon=0.003, power=2.0):\n",
    "    steps = torch.linspace(0, timesteps, steps=timesteps + 1, dtype=torch.float32)\n",
    "    f_t = (\n",
    "        torch.cos(((steps / timesteps + epsilon) / (1.0 + epsilon)) * math.pi * 0.5)\n",
    "        ** power\n",
    "    )\n",
    "    # betas = torch.clip(1.0 - f_t[1:] / f_t[:timesteps], 0.0, 0.999)\n",
    "    betas = torch.clip(1.0 - f_t[1:] / f_t[:timesteps], 0.0, 0.999)\n",
    "\n",
    "    return betas\n",
    "\n",
    "betas = _cosine_variance_schedule(states, power=2.0)\n",
    "alphas = 1.0 - betas\n",
    "alphas_bar = alphas.cumprod(dim=-1)\n",
    "sqrt_alpha_bar = alphas_bar.sqrt()\n",
    "sqrt_1_sub_alpha_b = (1.0 - alphas_bar).sqrt()\n",
    "\n",
    "def forward_diffusion(\n",
    "        clean_data: torch.Tensor, noise : torch.Tensor, target: torch.Tensor=None, keep_intermediate: bool = False) -> torch.Tensor:\n",
    "    if keep_intermediate:\n",
    "        images = [clean_data]\n",
    "\n",
    "        for t in range(states-1):\n",
    "            image_scale = (1-betas[t]).sqrt()\n",
    "            noise_scale = betas[t].sqrt()\n",
    "            noised = image_scale * images[-1] + noise_scale * torch.randn_like(\n",
    "                clean_data\n",
    "            )\n",
    "            # noised = torch.clip(noised, min=-1, max=1)\n",
    "            images.append(noised)\n",
    "\n",
    "        # concatenate each step into one image for for each sample\n",
    "        return torch.cat(images, dim=2)\n",
    "\n",
    "    else:\n",
    "        image_scale = sqrt_alpha_bar.gather(0, target).reshape(\n",
    "            clean_data.shape[0], 1, 1, 1\n",
    "        )\n",
    "        noise_scale = sqrt_1_sub_alpha_b.gather(0, target).reshape(\n",
    "            clean_data.shape[0], 1, 1, 1\n",
    "        )\n",
    "        noised = image_scale * clean_data + noise_scale * noise\n",
    "        # noised = torch.clip(noised, min=-1, max=1)\n",
    "        return noised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "tensor([3, 5, 4, 6, 5, 5, 1, 7])\n",
      "noised: tensor([[[[ 0.7960],\n",
      "          [-0.0114],\n",
      "          [ 0.7960],\n",
      "          [-0.0114],\n",
      "          [-0.0114],\n",
      "          [-0.0114],\n",
      "          [-0.0114],\n",
      "          [ 0.7960]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5706],\n",
      "          [-0.0156],\n",
      "          [ 0.5706],\n",
      "          [-0.0156],\n",
      "          [-0.0156],\n",
      "          [-0.0156],\n",
      "          [-0.0156],\n",
      "          [ 0.5706]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6918],\n",
      "          [-0.0137],\n",
      "          [ 0.6918],\n",
      "          [-0.0137],\n",
      "          [-0.0137],\n",
      "          [-0.0137],\n",
      "          [-0.0137],\n",
      "          [ 0.6918]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4355],\n",
      "          [-0.0172],\n",
      "          [ 0.4355],\n",
      "          [-0.0172],\n",
      "          [-0.0172],\n",
      "          [-0.0172],\n",
      "          [-0.0172],\n",
      "          [ 0.4355]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5706],\n",
      "          [-0.0156],\n",
      "          [ 0.5706],\n",
      "          [-0.0156],\n",
      "          [-0.0156],\n",
      "          [-0.0156],\n",
      "          [-0.0156],\n",
      "          [ 0.5706]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5706],\n",
      "          [-0.0156],\n",
      "          [ 0.5706],\n",
      "          [-0.0156],\n",
      "          [-0.0156],\n",
      "          [-0.0156],\n",
      "          [-0.0156],\n",
      "          [ 0.5706]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9439],\n",
      "          [-0.0060],\n",
      "          [ 0.9439],\n",
      "          [-0.0060],\n",
      "          [-0.0060],\n",
      "          [-0.0060],\n",
      "          [-0.0060],\n",
      "          [ 0.9439]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2898],\n",
      "          [-0.0184],\n",
      "          [ 0.2898],\n",
      "          [-0.0184],\n",
      "          [-0.0184],\n",
      "          [-0.0184],\n",
      "          [-0.0184],\n",
      "          [ 0.2898]]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 4 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sunje\\OneDrive\\Skrivebord\\Theo\\DDPM-hierarchical\\1DDDPM.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sunje/OneDrive/Skrivebord/Theo/DDPM-hierarchical/1DDDPM.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m noised \u001b[39m=\u001b[39m forward_diffusion(clean_data\u001b[39m=\u001b[39mflip, noise\u001b[39m=\u001b[39mnoise, target\u001b[39m=\u001b[39mt, keep_intermediate\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sunje/OneDrive/Skrivebord/Theo/DDPM-hierarchical/1DDDPM.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnoised:\u001b[39m\u001b[39m\"\u001b[39m, noised)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sunje/OneDrive/Skrivebord/Theo/DDPM-hierarchical/1DDDPM.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m pred \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39;49mcat((noised, t)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sunje/OneDrive/Skrivebord/Theo/DDPM-hierarchical/1DDDPM.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(noised\u001b[39m-\u001b[39mpred)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 4 and 1"
     ]
    }
   ],
   "source": [
    "data = torch.rand(8*100).round().reshape(-1, 8, 1)\n",
    "\n",
    "model = nn.Sequential(nn.Linear(2, 50), nn.GELU(), nn.Linear(50, 1))\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for i, flip in enumerate(data):\n",
    "    print(i, flip)\n",
    "    noise = torch.randn(1)\n",
    "    t = torch.randint(0, states-1, size=(8,))\n",
    "    print(t)\n",
    "    noised = forward_diffusion(clean_data=flip, noise=noise, target=t, keep_intermediate=False)\n",
    "    print(\"noised:\", noised)\n",
    "    pred = model(torch.cat((noised, t)))\n",
    "    loss = torch.mean(noised-pred)**2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
